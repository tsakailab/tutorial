{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/tutorial/blob/main/pytorch/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEaB9v4_I8CT"
      },
      "source": [
        "pytorchで転移学習やらモデルの作成やらをやってみよう！というゼミ資料です．\n",
        "\n",
        "最初の方は転移学習について話しています．\n",
        "\n",
        "このコードは前半については[公式のチュートリアル](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)をほぼコピペしています．\n",
        "\n",
        "説明がかなり雑な部分が多いので，気づいた人は説明の追加をしていただければ非常に助かります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vc03CJZp5KeL"
      },
      "source": [
        "#@title ## Download and extract data zipfile\n",
        "\n",
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip hymenoptera_data.zip -d ./\n",
        "\n",
        "ants = glob.glob('./hymenoptera_data/train/ants/*')\n",
        "bees = glob.glob('./hymenoptera_data/train/bees/*')\n",
        "f=lambda x: np.array(Image.open(x))\n",
        "ants = np.array(list(map(f,ants)))\n",
        "bees = np.array(list(map(f,bees)))\n",
        "data = np.concatenate((ants,bees),0)\n",
        "labels = np.concatenate((np.zeros(len(ants)),np.ones(len(bees))),0).astype('int64')\n",
        "\n",
        "ants_val = glob.glob('./hymenoptera_data/train/ants/*')\n",
        "bees_val = glob.glob('./hymenoptera_data/train/bees/*')\n",
        "f=lambda x: np.array(Image.open(x))\n",
        "ants_val = np.array(list(map(f,ants_val)))\n",
        "bees_val = np.array(list(map(f,bees_val)))\n",
        "data_val = np.concatenate((ants_val,bees_val),0)\n",
        "labels = np.concatenate((np.zeros(len(ants_val)),np.ones(len(bees_val))),0).astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAH4-vwW5qGJ"
      },
      "source": [
        "# dataloader作り\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = './hymenoptera_data/'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYKeOR4X7KBZ"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TGvE0phi7Uc-"
      },
      "source": [
        "#@title ## Define some function(training, printing result)\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "def train_model_tqdm(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_loss,val_loss,train_acc,val_acc = 0,0,0,0\n",
        "    with tqdm(range(num_epochs)) as bar:\n",
        "        for epoch in bar:\n",
        "            bar.set_description('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            \n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                #print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                #    phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                if phase=='train':\n",
        "                    train_loss = epoch_loss\n",
        "                    train_acc = epoch_acc\n",
        "                else:\n",
        "                    val_loss = epoch_loss\n",
        "                    val_acc = epoch_acc\n",
        "            bar.set_postfix(OrderedDict(train_loss='{:.4f}'.format(train_loss), \n",
        "                                        train_accuracy = '{:.4f}'.format(train_acc),\n",
        "                                        val_loss='{:.4f}'.format(val_loss), \n",
        "                                        val_accuracy = '{:.4f}'.format(val_acc)))\n",
        "            print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzMnObCx7XiA"
      },
      "source": [
        "# make model\n",
        "model = models.resnet18(pretrained=True)\n",
        "#model = model = models.vgg16(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u5yV7au7Yke"
      },
      "source": [
        "# Train model!\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAQrmLTJ7cO3"
      },
      "source": [
        "visualize_model(model_conv)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qt4vUjdLXuT"
      },
      "source": [
        "以下はtutorialにない内容．\n",
        "\n",
        "できたら便利だという事を武田の独断と偏見で追加しています．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b58w8J6NLU08"
      },
      "source": [
        "# tqdmを使ってみる\n",
        "# train_model_tqdmという関数を作っておきました．引数は同じなので，使ってみて下さい．\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRG3qOGgWy5s"
      },
      "source": [
        "# batch_sizeを変えてみる\n",
        "# 先に宣言したimshowあたりで見てみてください．\n",
        "\n",
        "#\n",
        "# batch_sizeを変えたdataloaders作成\n",
        "#\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "print(classes)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "7uDeBlJpLyV-"
      },
      "source": [
        "#@title ##難しいので折り畳み\n",
        "# MRIグループ向け．\n",
        "# 既に全データがnumpyで保存されているとき，どのようにdataloadersを作る？\n",
        "# ヒント：クラスを宣言することが必要です．\n",
        "# [答えはここに]内に武田が書いたmydatasetsというクラスがあります．\n",
        "# 殆ど最小限の構造になっているはずなので，見てみてほしい．\n",
        "\n",
        "# 全部盛りnumpyファイルの作成\n",
        "data = data # 画像データ\n",
        "labels = labels # ラベルデータ(アリ:0,ハチ:1)\n",
        "\n",
        "#\n",
        "# datasetクラスの宣言\n",
        "#\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "data_train = mydatasets(data, labels, data_transforms['train'])\n",
        "train_loaders = torch.utils.data.DataLoader(data_train, batch_size=2, shuffle=True)\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_loaders))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "sw8_-y-eQEFe"
      },
      "source": [
        "#@title ##答えはここに\n",
        "# こんな感じのクラスを作成すれば達成できます．\n",
        "class mydatasets(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, transforms=None):\n",
        "        self.data = data # データはdataという変数に格納されます．\n",
        "        self.label = labels # ラベルはlabelという変数に．\n",
        "        self.datanum = len(self.data) # コレを設定すると，総データ数をdataloaderが管理してくれます．\n",
        "        self.transforms = transforms # data augmentation(データ拡張)の設定を保存．\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.datanum\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        out_data = Image.fromarray(self.data[idx]) # データ読み取り\n",
        "        out_label = self.label[idx]\n",
        "        if self.transforms:\n",
        "            out_data = self.transforms(out_data)\n",
        "        return out_data, out_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGVR5ylfQdzN"
      },
      "source": [
        "# modelをプリントしてみる\n",
        "# modelはどのような構造となっているのかを確認してみて下さい．\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlGN6hb8Rlj_"
      },
      "source": [
        "# かなり長い文字列が表示されたと思います．\n",
        "# では，VGG16のものを表示してみてください．\n",
        "\n",
        "\n",
        "# 多少は短いものが表示されると思います．"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Gn3XNZucagN4"
      },
      "source": [
        "#@title ##答え\n",
        "model = models.vgg16(pretrained=True)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAPCV_hxaVAw"
      },
      "source": [
        "# VGG16の特徴抽出部より特徴抽出部を抜き出してください．\n",
        "# featuresとある部分がそれに対応します．\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "M4cPvD2Ea2I9"
      },
      "source": [
        "#@title ##答え\n",
        "feature_extraction = model.features\n",
        "print(feature_extraction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIdiDXrrbKWQ"
      },
      "source": [
        "# 抜きだした特徴抽出部から一部をさらに取り出してください．\n",
        "# 何処でもいいですが，悩むのであれば最後から2段目のMaxPooling層までを抜き出してみて下さい．\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Dewf61hDbbna"
      },
      "source": [
        "#@title ##答え\n",
        "feature_extraction = model.features\n",
        "layers = feature_extraction[:23]\n",
        "print(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V3U4H4RbsN1"
      },
      "source": [
        "# 抜き出した層の重みを比べてみて下さい．\n",
        "# 保存されているはずです．\n",
        "\n",
        "# こうして転移学習する層数を変えることができます．\n",
        "# 層数が少なければどのような特徴が抽出されるか，逆に層が厚い場合はどうなのか，考えてみて下さい．\n",
        "# 受容野とかそういう話です．\n",
        "# 分からなければ松尾とかが詳しいはずです．聞いてみて下さい．"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "O991yIDEbwrO"
      },
      "source": [
        "#@title ##答え\n",
        "feature_extraction = model.features\n",
        "layers = feature_extraction[:23]\n",
        "\n",
        "print(feature_extraction[0].weight == layers[0].weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6_DMRxjcnG5"
      },
      "source": [
        "# 御託はそろそろとして，モデルを自分で組んでみましょう．\n",
        "# ひな型を武田が用意しました．\n",
        "# 1層の畳み込み層のみで構成されるネットワークを作ってみましょう．\n",
        "# 入力は(224,224,3)の3チャネル画像を想定します．\n",
        "# つまりinput_channelは3です．公式のAPIを見に行ったりして書いてみて下さい．\n",
        "# 公式API:https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "# 記入する際，out_channelを決定する必要があると思います．\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = ___\n",
        "        self.conv = ___ # ここに記入\n",
        "        self.fc1 = nn.Linear(out_channel,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.view(x.shape[0],28*28*64)\n",
        "        x = self.fc1(x)   #上の部分をしっかり記入できていれば動くようになっています．\n",
        "\n",
        "        return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lHG9INaDepp5"
      },
      "source": [
        "#@title ##答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = 64\n",
        "        self.conv = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1)\n",
        "        self.fc1 = nn.Linear(out_channel*224*224,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.shape[0],224*224*64)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ProkNjxse0f7"
      },
      "source": [
        "# 作成したモデルを学習させてみましょう！\n",
        "# 多分ですが，わけわからん事になります．\n",
        "# (最適化関数をAdamにすることで少しはマシになります．やってみてもよろし)\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-q-croCflul"
      },
      "source": [
        "# 活性化関数を入れてみる\n",
        "# たまに聞く活性化関数なるものを導入してみましょう．\n",
        "# 特徴抽出を行うレイヤーの後ろに置きます．\n",
        "# 今回はReLUを使ってみて下さい．\n",
        "\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = ___\n",
        "        self.conv = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1) # ここに記入\n",
        "        self.activate = ____ # ReLUを導入してみましょう．\n",
        "        self.fc1 = nn.Linear(224*224*out_channel,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activate(x)\n",
        "        \n",
        "        x = x.view(x.shape[0],224*224*64)\n",
        "        x = self.fc1(x)   #上の部分をしっかり記入できていれば動くようになっています．\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3ZBVCwKoi9G_"
      },
      "source": [
        "#@title ##答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = 64\n",
        "        self.conv = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1) # ここに記入\n",
        "        self.activate = torch.nn.ReLU() # ReLUを導入してみましょう．\n",
        "        self.fc1 = nn.Linear(out_channel*224*224,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activate(x)\n",
        "        \n",
        "        x = x.view(x.shape[0],224*224*64)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "rOw50MfzkUOL"
      },
      "source": [
        "#@title ##学習用セル\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQGHk_27jVkI"
      },
      "source": [
        "# Poolingもしてみましょう．\n",
        "# VGGにも含まれるMaxPooling層を導入します．\n",
        "# 特徴抽出部のすぐ後ろに入れてみましょう．\n",
        "# 今回はforwardも自力で書き換えてみて下さい．\n",
        "# チャネル数を変えてみてもいいかもしれません．\n",
        "\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = ___\n",
        "        self.conv = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1) # ここに記入\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.fc1 = nn.Linear(out_channel*112*112,2)\n",
        "        self.pooling = ___ #ここに記入してみて下さい．\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activate(x)\n",
        "        \n",
        "        x = x.view(x.shape[0],112*112*64)\n",
        "        x = self.fc1(x)   #上の部分をしっかり記入できていれば動くようになっています．\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KSEJAdXpjwLQ"
      },
      "source": [
        "#@title ##答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = 64\n",
        "        self.conv = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1) # ここに記入\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.fc1 = nn.Linear(out_channel*112*112,2)\n",
        "        self.pooling = torch.nn.MaxPool2d(2) #ここに記入してみて下さい．\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activate(x)\n",
        "        x = self.pooling(x)\n",
        "\n",
        "        x = x.view(x.shape[0],112*112*64)\n",
        "        x = self.fc1(x)   #上の部分をしっかり記入できていれば動くようになっています．\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "F9gtKlnjj1eD"
      },
      "source": [
        "#@title ##学習用セル(学習が進まなかったのでここだけAdam)\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnvFVAKTkd-7"
      },
      "source": [
        "# では，特徴抽出部を増やしてみましょう．\n",
        "# 一気に2層ほど増やしてみることにします．\n",
        "# 今回はヒント無しです．答えは用意しておきますが，実際に書いてみて下さい．\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = ___\n",
        "        self.conv = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1)\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.fc1 = nn.Linear(out_channel,2)\n",
        "        self.pooling = torch.nn.MaxPool2d(2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activate(x)\n",
        "        x = self.pooling(x)\n",
        "        \n",
        "        x = x.view(x.shape[0],28*28*64)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_UEaSVgbk8tT"
      },
      "source": [
        "#@title ##答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        out_channel = 64\n",
        "        self.conv1 = torch.nn.Conv2d(3,out_channel,3,bias=True,padding = 1)\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.pooling = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = torch.nn.Conv2d(out_channel,out_channel*2,3,bias=True,padding = 1)\n",
        "        self.conv3 = torch.nn.Conv2d(out_channel*2,out_channel,3,bias=True,padding = 1)\n",
        "        \n",
        "        self.fc1 = nn.Linear(out_channel*28*28,2)\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.activate(x)\n",
        "        x = self.pooling(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activate(x)\n",
        "        x = self.pooling(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.activate(x)\n",
        "        x = self.pooling(x)\n",
        "        x = x.view(x.shape[0],28*28*64)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "85yUkYesleJM"
      },
      "source": [
        "#@title ##学習用セル\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TRlLpxglfkG"
      },
      "source": [
        "# 少しはマシになったかもしれません．\n",
        "# そろそろネットワークを作る事にも慣れてきたことでしょう．\n",
        "# それでは，特徴抽出部を転移学習してみましょう．\n",
        "# 特徴抽出部だけを抜き出してきた時を思い出してみて下さい．\n",
        "\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = ___ # ここに記入\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.fc1 = nn.Linear(512*7*7,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0],512*7*7)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vqnv_BIsxWyM"
      },
      "source": [
        "#@title 答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.fc1 = nn.Linear(512*7*7,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.vgg(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0],512*7*7)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aovC5oCtyxCt"
      },
      "source": [
        "#@title ##学習用セル\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS9qPD6FzXH0"
      },
      "source": [
        "# 一応性能が出たと思います．\n",
        "# 転移学習の力を思い知って頂ければ幸い．\n",
        "# 転移学習しましたが，実際にはもうひと手間加えたい事があります．\n",
        "# それは学習不可にする事です．\n",
        "# 何故そうするかはパラメータ数が多すぎる事とかいろいろあるわけですが，まあ詳しくは割愛．と言うわけで学習不可，つまりfreezeしましょう．\n",
        "# どうすればよいかは調べれば出てくるので，実践してみて下さい．\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.fc1 = nn.Linear(512*7*7,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.vgg(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0],512*7*7)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "nZ-i-yq_z0b_"
      },
      "source": [
        "#@title 答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        for layer in self.vgg:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.fc1 = nn.Linear(512*7*7,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.vgg(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0],512*7*7)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "07H9rIkH0TDU"
      },
      "source": [
        "#@title ##学習用セル\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bHljvim0U_s"
      },
      "source": [
        "# できましたか？\n",
        "# 実際freezeできているか確認することはなかなか難しいと思います．\n",
        "# そんなところで，便利なライブラリを紹介します．\n",
        "# torchsummary君です．百聞は何とやらと言うわけで使ってみて下さい．便利さが分かります．(pip推奨．condaでインストールしようとすると変な事になります)\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "summary(model_ft,(3,224,224))\n",
        "# ちなみにこのtorchsummary君ですが，0番目のGPUにモデルが載っている事を前提にできているみたいです．\n",
        "# 複数GPUや，CPUを使う場合は利用できないのでご注意を．\n",
        "# ここでtrainable parameterに振られている方はfreezeできていないのでやり直しです．"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSWFRey35Y69"
      },
      "source": [
        "転移学習を実装する事に関してはマスターしたも同然です．\n",
        "\n",
        "後は自分で学んでいけるでしょう(ここまでちゃんとやった人はそもそも自力で調べられる人だと思いますが)\n",
        "\n",
        "ここから先は発展的内容になります．\n",
        "\n",
        "武田が知っていた方が面白いのではと思った事を書き連ねているだけです．\n",
        "\n",
        "もういいやという人はブラウザバック推奨．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lym5E3Hx3CYL"
      },
      "source": [
        "# さて，散々識別問題を解かせてきました．しかし実際にモデルは何処を見ているのでしょうか．\n",
        "# その基準を知ろうという試みとして，CAM(class activation map)があります．\n",
        "# 簡潔に言えば，モデルがどこを見て診断したか可視化したデータです．\n",
        "# これは酒井研の研究では細胞診，MRIで利用されていますね．\n",
        "# 詳しくはここでは触れません．調べてみてね．本項ではその実装について触れます．\n",
        "# 作り方は次セルに任せるとして，このセルではモデルの出力を増やしてみましょう．\n",
        "\n",
        "# モデルはさっきまで使っていたものとします．\n",
        "# このモデルのうち，特徴抽出部から出て来たものをついでに出力してみましょう．\n",
        "# どうすれば出力できるでしょうか？\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.fc1 = nn.Linear(512*7*7,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.vgg(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0],512*7*7)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "J8D4B6rO8ECY"
      },
      "source": [
        "#@title 答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.fc1 = nn.Linear(512*7*7,2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.vgg(x)\n",
        "        feature_map = x.clone()\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0],512*7*7)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x, feature_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwOpQa8O8QyX"
      },
      "source": [
        "実際に学習してみましょう．\n",
        "\n",
        "本来はちょいと学習用関数も変更する必要がありますが，今回は学習用セルに含めておきました．\n",
        "(0番目の出力が推論であることを想定しています．)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "A4ItZHIV79lW"
      },
      "source": [
        "#@title 学習用セル\n",
        "def train_model_tqdm(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_loss,val_loss,train_acc,val_acc = 0,0,0,0\n",
        "    with tqdm(range(num_epochs)) as bar:\n",
        "        for epoch in bar:\n",
        "            bar.set_description('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            \n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)[0]\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                #print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                #    phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                if phase=='train':\n",
        "                    train_loss = epoch_loss\n",
        "                    train_acc = epoch_acc\n",
        "                else:\n",
        "                    val_loss = epoch_loss\n",
        "                    val_acc = epoch_acc\n",
        "            bar.set_postfix(OrderedDict(train_loss='{:.4f}'.format(train_loss), \n",
        "                                        train_accuracy = '{:.4f}'.format(train_acc),\n",
        "                                        val_loss='{:.4f}'.format(val_loss), \n",
        "                                        val_accuracy = '{:.4f}'.format(val_acc)))\n",
        "            print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "#@title ##学習用セル\n",
        "model = my_model().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model_tqdm(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq3JK3fJ9PLV"
      },
      "source": [
        "# 学習が終わりましたね．\n",
        "# 実際に算出される特徴マップを見てみましょうか．\n",
        "img = Image.open('./hymenoptera_data/val/ants/Ant-1818.jpg')\n",
        "img = data_transforms['val'](img)\n",
        "imshow(img)\n",
        "feature_map = model_ft(img.unsqueeze(0).to(device))[1]\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "for x in range(1,6):\n",
        "    plt.subplot(1,5,x)\n",
        "    plt.imshow(feature_map.cpu().detach()[0][x], cmap='gray')\n",
        "\n",
        "# まあ，ようわからんわけです．\n",
        "# これは特徴抽出部の層を厚く取ったため，挟まれるPoolingでfeature mapのサイズが小さくなってしまっている事に起因しています．\n",
        "# 一応この特徴マップでもどこから特徴を取得しているかわかりますが，それでも分かりづらいわけです．"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqjfvh-gAMDo"
      },
      "source": [
        "# ではCAMに移ります．\n",
        "# CAMはGAP(Global average Pooling)層の入力として現れます．\n",
        "# これを導入すると殆どFCN(Fully Convolutional Network)となるわけですが，学術的話は一切やりません．調べて．\n",
        "# GAPはx.mean([2,3])で実装できます．楽ですね．\n",
        "# CAMは各クラスの数だけである必要があります．\n",
        "# 従って，512channelまで増えた特徴マップを2チャネルに落とす必要があるわけで．\n",
        "# これは何層かConv2dを挟んで対応します．\n",
        "# まあなんやかんや言ってますが，私の説明で分かるとも思えないので，実際にやってみましょう．難しいと思いますので，答えを見たりしてやってみて下さい．\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Vw8L7MhfBSkW"
      },
      "source": [
        "#@title 答え\n",
        "class my_model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        for layer in self.vgg:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.activate = torch.nn.ReLU()\n",
        "        self.avgpool = models.vgg16().avgpool\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(512,128,3,padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(128,32,3,padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(32,2,2,padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.vgg(x)\n",
        "        x = self.conv(x)\n",
        "        cam = x.clone()\n",
        "        x = x.mean([2,3])\n",
        "        \n",
        "        return x, cam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tYtbzouJCLI9"
      },
      "source": [
        "#@title 学習用セル\n",
        "def train_model_tqdm(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_loss,val_loss,train_acc,val_acc = 0,0,0,0\n",
        "    with tqdm(range(num_epochs)) as bar:\n",
        "        for epoch in bar:\n",
        "            bar.set_description('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            \n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)[0]\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                #print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                #    phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                if phase=='train':\n",
        "                    train_loss = epoch_loss\n",
        "                    train_acc = epoch_acc\n",
        "                else:\n",
        "                    val_loss = epoch_loss\n",
        "                    val_acc = epoch_acc\n",
        "            bar.set_postfix(OrderedDict(train_loss='{:.4f}'.format(train_loss), \n",
        "                                        train_accuracy = '{:.4f}'.format(train_acc),\n",
        "                                        val_loss='{:.4f}'.format(val_loss), \n",
        "                                        val_accuracy = '{:.4f}'.format(val_acc)))\n",
        "            print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "#@title ##学習用セル\n",
        "model = my_model().to(device)\n",
        "summary(model,(3,224,224))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "model_ft = train_model_tqdm(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCmoIedFC70s"
      },
      "source": [
        "# CAMを出力してみましょう．\n",
        "# 実行するたび別のものが表示されるので，いろいろと試してみて下さい．\n",
        "# ちなみに推論されたクラスはCAMの上にある文字が赤くなります．\n",
        "import random\n",
        "target = ['ants','bees'][1]\n",
        "img = Image.open('./hymenoptera_data/val/{}/'.format(target) + random.choice(os.listdir('./hymenoptera_data/val/{}/'.format(target))))\n",
        "img = data_transforms['val'](img)\n",
        "imshow(img)\n",
        "outputs, cam = model_ft(img.unsqueeze(0).to(device))\n",
        "_, preds = torch.max(outputs, 1)\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "for x in range(2):\n",
        "    plt.subplot(1,2,x+1)\n",
        "    plt.imshow(cam.cpu().detach()[0][x], cmap='gray', vmin=cam.min(),vmax=cam.max())\n",
        "    plt.title(class_names[x],color=\"red\" if preds == x else 'black')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}